---
name: memory-manager
description: ğŸš¨ MANDATORY SKILL - LOAD ON EVERY SESSION! Prevents context overflow. You MUST follow the STRICT PROTOCOL below for EVERY tool call. Failure = context overflow = crash.
metadata: {"clawdbot":{"emoji":"ğŸ§ ","os":["darwin","linux"],"requires":{"bins":["python3"]},"priority":"critical","autoLoad":true}}
---

# ğŸš¨ MEMORY MANAGER - STRICT PROTOCOL

## â›” STOP! READ BEFORE ANY ACTION!

**This protocol is MANDATORY for EVERY tool call, EVERY response, EVERY session.**

---

## ğŸ”´ THE GOLDEN RULES (MEMORIZE!)

### Rule 1: NEVER use native tools for external data
```
âŒ BANNED: web_fetch, curl, wget
âœ… USE: python3 {baseDir}/scripts/smart_fetch.py --url URL --context-percent X

âŒ BANNED: cat large_file, read entire files
âœ… USE: python3 {baseDir}/scripts/smart_read.py --file FILE --context-percent X
```

### Rule 2: EVERY 3 tool calls â†’ CHECK CONTEXT
```bash
# After every 3 tool calls, run this:
echo "Context check" && python3 {baseDir}/scripts/token_counter.py --text "current estimate"
```

### Rule 3: If context > 50% â†’ SWITCH TO SURVIVAL MODE
- Use `--signatures-only` for code files
- Use `--force-summary` for all fetches
- Keep responses under 500 tokens
- NO explanations, just facts

### Rule 4: If context > 70% â†’ EMERGENCY STOP
```
ğŸš¨ STOP ALL OPERATIONS!
Tell user: "ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¿ĞµÑ€ĞµĞ¿Ğ¾Ğ²Ğ½ĞµĞ½Ğ¸Ğ¹ (>70%). ĞŸĞ¾Ñ‚Ñ€Ñ–Ğ±Ğ½Ğ¾ /new session."
DO NOT continue!
```

### Rule 5: MAX 2 subagents, MINIMAL context
```
âŒ spawn(full_conversation_history)
âœ… spawn(only_task_description_under_500_tokens)
```

### Rule 6: API calls return BIG JSON â€” LIMIT RESULTS
```
âŒ moltbook_search() â†’ returns 50+ posts â†’ 30K tokens â†’ OVERFLOW
âœ… moltbook_search(limit=5) â†’ 5 posts â†’ 2K tokens â†’ SAFE

âŒ moltbook_get_comments() â†’ all comments â†’ 20K tokens
âœ… moltbook_get_comments(limit=3) â†’ 3 comments â†’ 1K tokens
```

### Rule 7: USE SMART TOOLS FOR EVERYTHING
```
BEFORE any external data operation:
1. Check current context %
2. Use smart_fetch / smart_read (NOT native tools)
3. They auto-adjust output based on your budget

smart_fetch at 30% context â†’ returns 10K max
smart_fetch at 70% context â†’ returns 2K max (auto!)
```

### Rule 8: LIMIT ALL API RESPONSES
```
EVERY API call must have limits:

âŒ search() â†’ unknown size â†’ potential overflow
âœ… search(limit=5) â†’ controlled size â†’ safe

âŒ get_feed() â†’ 50 posts â†’ 30K tokens
âœ… get_feed(limit=3) â†’ 3 posts â†’ 2K tokens

NO EXCEPTIONS. Always pass limit parameter.
```

### Rule 9: SELF-MONITOR CONTINUOUSLY
```
After every 3 tool calls:
â†’ Estimate current context %
â†’ If > 60%: switch to minimal outputs
â†’ If > 80%: finish current task, no new tasks

You can keep working, just be economical.
```

### Rule 10: CACHE IS YOUR FRIEND
```
Got summary but need details later?
â†’ Full content is cached
â†’ Use: cache_manager --get ID --section "specific part"
â†’ Gets only what you need (500 tokens vs 50K)

This lets you work autonomously without overflow.
```

---

## ğŸ“‹ PRE-ACTION CHECKLIST (Run mentally before EVERY action)

```
â–¡ Is this tool call necessary?
â–¡ Can I get the same info with less tokens?
â–¡ Am I using smart_fetch/smart_read instead of native?
â–¡ Have I checked context recently?
â–¡ Is my response concise (not verbose)?
```

---

## ğŸ› ï¸ TOOLS REFERENCE

### CHECK CONTEXT (do this often!)
```bash
python3 {baseDir}/scripts/token_counter.py --text "your text"
# Returns: {"tokens": X, "percent": Y, "warning": "OK/MEDIUM/HIGH/CRITICAL"}
```

### SMART FETCH (URLs) - ALWAYS USE THIS!
```bash
python3 {baseDir}/scripts/smart_fetch.py \
  --url "https://example.com" \
  --context-percent 0.5
```

### SMART READ (Files) - ALWAYS USE THIS!
```bash
# For code - signatures only
python3 {baseDir}/scripts/smart_read.py --file code.py --signatures-only

# For any file with context awareness
python3 {baseDir}/scripts/smart_read.py --file doc.md --context-percent 0.6
```

### GET CACHED FULL CONTENT (if needed)
```bash
python3 {baseDir}/scripts/cache_manager.py --get CACHE_ID
python3 {baseDir}/scripts/cache_manager.py --get CACHE_ID --section "specific part"
```

### COMPRESS HISTORY (emergency)
```bash
python3 {baseDir}/scripts/compressor.py --input history.json --keep-recent 5
```

---

## ğŸ“Š CONTEXT BUDGET TABLE

| Your Context | Tool Output Budget | Response Length | Mode |
|--------------|-------------------|-----------------|------|
| < 40% | 10K tokens | Normal | Relaxed |
| 40-50% | 5K tokens | Concise | Careful |
| 50-70% | 2K tokens | Minimal | Survival |
| > 70% | 500 tokens | Emergency | STOP! |

---

## âš¡ QUICK DECISION TREE

```
Need external data?
â”œâ”€â”€ URL â†’ smart_fetch.py (auto-limits based on context!)
â”œâ”€â”€ File â†’ smart_read.py (auto-limits based on context!)
â””â”€â”€ API â†’ ALWAYS pass limit parameter

Context estimate?
â”œâ”€â”€ < 50% â†’ Full speed, smart tools handle it
â”œâ”€â”€ 50-70% â†’ Continue, tools auto-switch to minimal
â”œâ”€â”€ 70-85% â†’ Finish current task, then suggest /new
â””â”€â”€ > 85% â†’ Complete only current action, then /new

Spawning subagent?
â”œâ”€â”€ Context > 60%? â†’ NO, do it yourself
â”œâ”€â”€ Context < 60%? â†’ OK, max 2, minimal task description
â””â”€â”€ Task description > 500 tokens? â†’ Shorten it

Multiple tasks queued?
â”œâ”€â”€ Context < 50% â†’ Do them all
â”œâ”€â”€ Context 50-70% â†’ Do 2-3 more, then assess
â””â”€â”€ Context > 70% â†’ Do 1 more, then /new
```

---

## ğŸš« BANNED vs âœ… ALLOWED

```
âŒ web_fetch(url) â†’ uncontrolled 50K â†’ OVERFLOW
âœ… smart_fetch(url) â†’ auto-limited 2-10K â†’ SAFE

âŒ cat large_file â†’ uncontrolled 30K â†’ OVERFLOW  
âœ… smart_read(file) â†’ auto-limited â†’ SAFE

âŒ search() without limit â†’ 30K â†’ OVERFLOW
âœ… search(limit=5) â†’ controlled 2K â†’ SAFE

âŒ spawn 5 agents with full context â†’ 5x memory â†’ OVERFLOW
âœ… spawn 1-2 agents with task-only context â†’ SAFE

âŒ Keep working at 85% context â†’ next call = crash
âœ… At 80%+: finish task, start fresh session for new tasks
```

---

## ğŸ¤– MOLTBOOK/API SPECIFIC RULES

```
âš ï¸ EVERY API call returns JSON = TOKENS!

SAFE calls (~500 tokens):
- moltbook_create_post
- moltbook_like_post  
- moltbook_comment (short)

DANGEROUS calls (use limits!):
- moltbook_search(limit=5)      â†’ ~2K tokens âœ…
- moltbook_search()             â†’ ~30K tokens âŒ
- moltbook_get_feed(limit=3)    â†’ ~2K tokens âœ…
- moltbook_get_feed()           â†’ ~50K tokens âŒ

AUTONOMOUS WORKFLOW:
1. Do task (post, search, engage)
2. Check context estimate
3. If < 70%: continue to next task
4. If > 70%: finish current, suggest /new for more

You stay autonomous, just manage your budget.
```

---

## ğŸ’€ WHAT HAPPENS IF YOU IGNORE THIS

```
1. You use native web_fetch
2. Returns 50K tokens
3. Context jumps from 60% to 95%
4. Your next response triggers overflow
5. "Context overflow: prompt too large"
6. Session dies, state lost
7. User angry, has to start over
```

**DON'T BE THAT AGENT. FOLLOW THE PROTOCOL.**

---

## ğŸ“ Files in this skill

### v1.0 - Compress OLD
- `{baseDir}/scripts/token_counter.py` â€” count tokens
- `{baseDir}/scripts/compressor.py` â€” compress history
- `{baseDir}/scripts/budget_tracker.py` â€” track costs

### v2.0 - Optimize INCOMING
- `{baseDir}/scripts/smart_fetch.py` â€” URL fetch + auto-summary
- `{baseDir}/scripts/smart_read.py` â€” file read + auto-summary
- `{baseDir}/scripts/cache_manager.py` â€” temp storage

---

## ğŸ”§ Install

```bash
python3 -m pip install -r {baseDir}/requirements.txt
```

---

## ğŸ“ Session Start Checklist

When starting any session:
1. âœ… Load this skill
2. âœ… Remember: smart_fetch > web_fetch
3. âœ… Remember: smart_read > cat/read
4. âœ… Remember: check context every 3 tools
5. âœ… Remember: > 70% = STOP

---

**Created to prevent context overflow. Follow strictly. No exceptions.**
