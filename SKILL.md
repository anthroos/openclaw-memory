---
name: memory-manager
description: ğŸš¨ MANDATORY SKILL - LOAD ON EVERY SESSION! Prevents context overflow. You MUST follow the STRICT PROTOCOL below for EVERY tool call. Failure = context overflow = crash.
metadata: {"clawdbot":{"emoji":"ğŸ§ ","os":["darwin","linux"],"requires":{"bins":["python3"]},"priority":"critical","autoLoad":true}}
---

# ğŸš¨ MEMORY MANAGER - STRICT PROTOCOL

## â›” STOP! READ BEFORE ANY ACTION!

**This protocol is MANDATORY for EVERY tool call, EVERY response, EVERY session.**

---

## ğŸ”´ THE GOLDEN RULES (MEMORIZE!)

### Rule 1: NEVER use native tools for external data
```
âŒ BANNED: web_fetch, curl, wget
âœ… USE: python3 {baseDir}/scripts/smart_fetch.py --url URL --context-percent X

âŒ BANNED: cat large_file, read entire files
âœ… USE: python3 {baseDir}/scripts/smart_read.py --file FILE --context-percent X
```

### Rule 2: EVERY 3 tool calls â†’ CHECK CONTEXT
```bash
# After every 3 tool calls, run this:
echo "Context check" && python3 {baseDir}/scripts/token_counter.py --text "current estimate"
```

### Rule 3: If context > 50% â†’ SWITCH TO SURVIVAL MODE
- Use `--signatures-only` for code files
- Use `--force-summary` for all fetches
- Keep responses under 500 tokens
- NO explanations, just facts

### Rule 4: If context > 70% â†’ EMERGENCY STOP
```
ğŸš¨ STOP ALL OPERATIONS!
Tell user: "ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¿ĞµÑ€ĞµĞ¿Ğ¾Ğ²Ğ½ĞµĞ½Ğ¸Ğ¹ (>70%). ĞŸĞ¾Ñ‚Ñ€Ñ–Ğ±Ğ½Ğ¾ /new session."
DO NOT continue!
```

### Rule 5: MAX 2 subagents, MINIMAL context
```
âŒ spawn(full_conversation_history)
âœ… spawn(only_task_description_under_500_tokens)
```

### Rule 6: API calls return BIG JSON â€” LIMIT RESULTS
```
âŒ moltbook_search() â†’ returns 50+ posts â†’ 30K tokens â†’ OVERFLOW
âœ… moltbook_search(limit=5) â†’ 5 posts â†’ 2K tokens â†’ SAFE

âŒ moltbook_get_comments() â†’ all comments â†’ 20K tokens
âœ… moltbook_get_comments(limit=3) â†’ 3 comments â†’ 1K tokens
```

### Rule 7: ONE TASK AT A TIME
```
âŒ "Create post, then search, then engage 3 bots, then check reactions"
   = 6+ tool calls = OVERFLOW

âœ… "Create post" â†’ STOP â†’ wait for user
âœ… "Search for 3 bots" â†’ STOP â†’ wait for user  
âœ… "Engage 1 bot" â†’ STOP â†’ wait for user
```

### Rule 8: NO CHAIN REACTIONS
```
âŒ Tool call â†’ see result â†’ "let me also..." â†’ another tool â†’ "and also..."
   This KILLS context!

âœ… Tool call â†’ DONE. Report to user. Wait.
```

### Rule 9: YOUR ESTIMATES ARE WRONG
```
Your "49% context" is probably actually 80%+
Tool outputs are BIGGER than you think
When in doubt: STOP EARLIER, not later
```

---

## ğŸ“‹ PRE-ACTION CHECKLIST (Run mentally before EVERY action)

```
â–¡ Is this tool call necessary?
â–¡ Can I get the same info with less tokens?
â–¡ Am I using smart_fetch/smart_read instead of native?
â–¡ Have I checked context recently?
â–¡ Is my response concise (not verbose)?
```

---

## ğŸ› ï¸ TOOLS REFERENCE

### CHECK CONTEXT (do this often!)
```bash
python3 {baseDir}/scripts/token_counter.py --text "your text"
# Returns: {"tokens": X, "percent": Y, "warning": "OK/MEDIUM/HIGH/CRITICAL"}
```

### SMART FETCH (URLs) - ALWAYS USE THIS!
```bash
python3 {baseDir}/scripts/smart_fetch.py \
  --url "https://example.com" \
  --context-percent 0.5
```

### SMART READ (Files) - ALWAYS USE THIS!
```bash
# For code - signatures only
python3 {baseDir}/scripts/smart_read.py --file code.py --signatures-only

# For any file with context awareness
python3 {baseDir}/scripts/smart_read.py --file doc.md --context-percent 0.6
```

### GET CACHED FULL CONTENT (if needed)
```bash
python3 {baseDir}/scripts/cache_manager.py --get CACHE_ID
python3 {baseDir}/scripts/cache_manager.py --get CACHE_ID --section "specific part"
```

### COMPRESS HISTORY (emergency)
```bash
python3 {baseDir}/scripts/compressor.py --input history.json --keep-recent 5
```

---

## ğŸ“Š CONTEXT BUDGET TABLE

| Your Context | Tool Output Budget | Response Length | Mode |
|--------------|-------------------|-----------------|------|
| < 40% | 10K tokens | Normal | Relaxed |
| 40-50% | 5K tokens | Concise | Careful |
| 50-70% | 2K tokens | Minimal | Survival |
| > 70% | 500 tokens | Emergency | STOP! |

---

## âš¡ QUICK DECISION TREE

```
Need external data?
â”œâ”€â”€ URL â†’ smart_fetch.py (NOT web_fetch!)
â”œâ”€â”€ File â†’ smart_read.py (NOT cat/read!)
â””â”€â”€ API â†’ smart_fetch.py with API URL

Context feeling heavy?
â”œâ”€â”€ < 50% â†’ Continue carefully
â”œâ”€â”€ 50-70% â†’ Switch to survival mode
â””â”€â”€ > 70% â†’ STOP, tell user to /new

Spawning subagent?
â”œâ”€â”€ Context > 50%? â†’ NO, don't spawn
â”œâ”€â”€ Task description > 500 tokens? â†’ Shorten it
â””â”€â”€ More than 2 agents? â†’ NO, max 2
```

---

## ğŸš« BANNED PATTERNS

```
âŒ "Let me fetch this URL..." â†’ web_fetch â†’ 50K tokens â†’ OVERFLOW
âŒ "I'll read the entire file..." â†’ cat â†’ 30K tokens â†’ OVERFLOW
âŒ "Here's a detailed explanation..." â†’ 5K response â†’ OVERFLOW
âŒ "Spawning 5 expert agents..." â†’ 5x context â†’ OVERFLOW
âŒ "Let me also engage these 3 bots..." â†’ chain reaction â†’ OVERFLOW
âŒ "Checking reactions on my post..." â†’ unnecessary call â†’ OVERFLOW

âœ… "Using smart_fetch..." â†’ 2K summary â†’ SAFE
âœ… "Reading signatures only..." â†’ 500 tokens â†’ SAFE
âœ… "Short answer: X" â†’ 200 tokens â†’ SAFE
âœ… "Spawning 1 focused agent..." â†’ minimal context â†’ SAFE
âœ… "Done. One post created." â†’ STOP â†’ SAFE
```

---

## ğŸ¤– MOLTBOOK/API SPECIFIC RULES

```
âš ï¸ EVERY API call returns JSON = TOKENS!

moltbook_create_post    â†’ ~500 tokens (OK)
moltbook_search         â†’ ~5K-30K tokens (DANGER!)
moltbook_get_feed       â†’ ~10K-50K tokens (DANGER!)
moltbook_get_comments   â†’ ~2K-20K tokens (DANGER!)

ALWAYS use limit parameter:
- search(limit=5) not search()
- get_feed(limit=3) not get_feed()
- get_comments(limit=3) not get_comments()

RESIST THE URGE to:
- "Check how my post is doing" â†’ unnecessary
- "Engage multiple bots at once" â†’ do ONE
- "Search for more content" â†’ you have enough
```

---

## ğŸ’€ WHAT HAPPENS IF YOU IGNORE THIS

```
1. You use native web_fetch
2. Returns 50K tokens
3. Context jumps from 60% to 95%
4. Your next response triggers overflow
5. "Context overflow: prompt too large"
6. Session dies, state lost
7. User angry, has to start over
```

**DON'T BE THAT AGENT. FOLLOW THE PROTOCOL.**

---

## ğŸ“ Files in this skill

### v1.0 - Compress OLD
- `{baseDir}/scripts/token_counter.py` â€” count tokens
- `{baseDir}/scripts/compressor.py` â€” compress history
- `{baseDir}/scripts/budget_tracker.py` â€” track costs

### v2.0 - Optimize INCOMING
- `{baseDir}/scripts/smart_fetch.py` â€” URL fetch + auto-summary
- `{baseDir}/scripts/smart_read.py` â€” file read + auto-summary
- `{baseDir}/scripts/cache_manager.py` â€” temp storage

---

## ğŸ”§ Install

```bash
python3 -m pip install -r {baseDir}/requirements.txt
```

---

## ğŸ“ Session Start Checklist

When starting any session:
1. âœ… Load this skill
2. âœ… Remember: smart_fetch > web_fetch
3. âœ… Remember: smart_read > cat/read
4. âœ… Remember: check context every 3 tools
5. âœ… Remember: > 70% = STOP

---

**Created to prevent context overflow. Follow strictly. No exceptions.**
